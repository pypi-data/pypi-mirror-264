# Generated by the protocol buffer compiler.  DO NOT EDIT!
# sources: chunks.proto, conversational.proto, ingestion.proto, search.proto
# plugin: python-betterproto
from dataclasses import dataclass
from typing import TYPE_CHECKING, Dict, List, Optional

import betterproto
import betterproto.lib.google.protobuf as betterproto_lib_google_protobuf
import grpclib
from betterproto.grpc.grpclib_server import ServiceBase

if TYPE_CHECKING:
    import grpclib.server
    from betterproto.grpc.grpclib_client import MetadataLike
    from grpclib.metadata import Deadline


class FinishReason(betterproto.Enum):
    content_filter = 0
    stop = 1
    length = 2


@dataclass(eq=False, repr=False)
class SourceReference(betterproto.Message):
    system: str = betterproto.string_field(1)
    """
    Source system of the document e.g. confluence, slack, local_file_system
    """

    system_version: str = betterproto.string_field(2)
    """Version of the source system e.g. 1.0.0"""

    connection_id: str = betterproto.string_field(3)
    """
    Connection id to the source system e.g. confluence space id, slack channel
    id, local file hostname
    """

    document_id: str = betterproto.string_field(4)
    """
    Document id in the source system e.g. confluence page id, slack message id,
    local file path
    """

    document_version: str = betterproto.string_field(5)
    """
    Document version in the source system e.g. confluence page version, slack
    message version, local file version hash
    """


@dataclass(eq=False, repr=False)
class ChunkReference(betterproto.Message):
    chunking_version: str = betterproto.string_field(1)
    """Chunking version e.g. 1.0.0"""

    chunk_id: str = betterproto.string_field(2)
    """
    chunk id is unique within the document, but not globally unique, it's
    actually the index of the chunk in the document
    """

    chunk_hash: str = betterproto.string_field(3)
    """SHA256 hash of the chunk body"""


@dataclass(eq=False, repr=False)
class RelevantChunk(betterproto.Message):
    """A chunk is a part of a document"""

    source: "SourceReference" = betterproto.message_field(1)
    """Source reference of the document"""

    chunk: "ChunkReference" = betterproto.message_field(2)
    """Chunk reference of the chunk"""

    relevance: "RelevantChunkRelevance" = betterproto.message_field(3)
    """Relevance of the chunk"""

    chunk_body: str = betterproto.string_field(4)
    """Chunk body"""

    document_metadata: "betterproto_lib_google_protobuf.Struct" = betterproto.message_field(5)
    """Document metadata"""


@dataclass(eq=False, repr=False)
class RelevantChunkRelevance(betterproto.Message):
    similarity_score: float = betterproto.float_field(1)
    """Simiarlity score of the chunk"""


@dataclass(eq=False, repr=False)
class IngestionResponse(betterproto.Message):
    success: bool = betterproto.bool_field(1)
    """Ingestion was successful"""

    error: Optional["betterproto_lib_google_protobuf.Struct"] = betterproto.message_field(
        2, optional=True, group="_error"
    )
    """Error message if ingestion failed"""


@dataclass(eq=False, repr=False)
class Query(betterproto.Message):
    semantic_query: str = betterproto.string_field(1)
    """Semantic query to execute"""


@dataclass(eq=False, repr=False)
class QueryRequest(betterproto.Message):
    count: Optional[int] = betterproto.uint32_field(1, optional=True, group="_count")
    """How many results to try to return (maximum number of results)"""

    query: "Query" = betterproto.message_field(2)
    """The query to execute"""


@dataclass(eq=False, repr=False)
class QueryResponse(betterproto.Message):
    success: bool = betterproto.bool_field(1)
    """Query was successful"""

    error: Optional["betterproto_lib_google_protobuf.Struct"] = betterproto.message_field(
        2, optional=True, group="_error"
    )
    """Error message if query failed"""

    relevant_chunks: List["RelevantChunk"] = betterproto.message_field(3)
    """List of relevant chunks"""


@dataclass(eq=False, repr=False)
class CreateResponse(betterproto.Message):
    choices: List["Choice"] = betterproto.message_field(1)
    created: int = betterproto.int32_field(2)
    id: str = betterproto.string_field(3)
    model: str = betterproto.string_field(4)
    object: str = betterproto.string_field(5)
    usage: "Usage" = betterproto.message_field(6)
    metadata: "Metadata" = betterproto.message_field(7)


@dataclass(eq=False, repr=False)
class Metadata(betterproto.Message):
    redaction: "Redaction" = betterproto.message_field(1)


@dataclass(eq=False, repr=False)
class Redaction(betterproto.Message):
    provider: str = betterproto.string_field(1)
    redaction_table: Dict[str, str] = betterproto.map_field(2, betterproto.TYPE_STRING, betterproto.TYPE_STRING)
    redacted_messages: List["Message"] = betterproto.message_field(3)


@dataclass(eq=False, repr=False)
class Usage(betterproto.Message):
    completion_tokens: int = betterproto.int32_field(1)
    prompt_tokens: int = betterproto.int32_field(2)
    total_tokens: int = betterproto.int32_field(3)


@dataclass(eq=False, repr=False)
class Choice(betterproto.Message):
    finish_reason: str = betterproto.string_field(1)
    index: int = betterproto.int32_field(2)
    message: "Message" = betterproto.message_field(3)


@dataclass(eq=False, repr=False)
class CreateRequest(betterproto.Message):
    model: str = betterproto.string_field(1)
    messages: List["Message"] = betterproto.message_field(2)


@dataclass(eq=False, repr=False)
class MessagePart(betterproto.Message):
    content: str = betterproto.string_field(1)


@dataclass(eq=False, repr=False)
class Message(betterproto.Message):
    content: str = betterproto.string_field(1)
    role: str = betterproto.string_field(2)


class IngestionStub(betterproto.ServiceStub):
    async def ingest_document(
        self,
        source_reference: "SourceReference",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "IngestionResponse":
        return await self._unary_unary(
            "/redactive.grpc.v1.Ingestion/IngestDocument",
            source_reference,
            IngestionResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )


class SearchStub(betterproto.ServiceStub):
    async def query_chunks(
        self,
        query_request: "QueryRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "QueryResponse":
        return await self._unary_unary(
            "/redactive.grpc.v1.Search/QueryChunks",
            query_request,
            QueryResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )


class ChatCompletionStub(betterproto.ServiceStub):
    async def create(
        self,
        create_request: "CreateRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "CreateResponse":
        return await self._unary_unary(
            "/redactive.grpc.v1.ChatCompletion/Create",
            create_request,
            CreateResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )


class IngestionBase(ServiceBase):
    async def ingest_document(self, source_reference: "SourceReference") -> "IngestionResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def __rpc_ingest_document(self, stream: "grpclib.server.Stream[SourceReference, IngestionResponse]") -> None:
        request = await stream.recv_message()
        response = await self.ingest_document(request)
        await stream.send_message(response)

    def __mapping__(self) -> Dict[str, grpclib.const.Handler]:
        return {
            "/redactive.grpc.v1.Ingestion/IngestDocument": grpclib.const.Handler(
                self.__rpc_ingest_document,
                grpclib.const.Cardinality.UNARY_UNARY,
                SourceReference,
                IngestionResponse,
            ),
        }


class SearchBase(ServiceBase):
    async def query_chunks(self, query_request: "QueryRequest") -> "QueryResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def __rpc_query_chunks(self, stream: "grpclib.server.Stream[QueryRequest, QueryResponse]") -> None:
        request = await stream.recv_message()
        response = await self.query_chunks(request)
        await stream.send_message(response)

    def __mapping__(self) -> Dict[str, grpclib.const.Handler]:
        return {
            "/redactive.grpc.v1.Search/QueryChunks": grpclib.const.Handler(
                self.__rpc_query_chunks,
                grpclib.const.Cardinality.UNARY_UNARY,
                QueryRequest,
                QueryResponse,
            ),
        }


class ChatCompletionBase(ServiceBase):
    async def create(self, create_request: "CreateRequest") -> "CreateResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def __rpc_create(self, stream: "grpclib.server.Stream[CreateRequest, CreateResponse]") -> None:
        request = await stream.recv_message()
        response = await self.create(request)
        await stream.send_message(response)

    def __mapping__(self) -> Dict[str, grpclib.const.Handler]:
        return {
            "/redactive.grpc.v1.ChatCompletion/Create": grpclib.const.Handler(
                self.__rpc_create,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateRequest,
                CreateResponse,
            ),
        }
