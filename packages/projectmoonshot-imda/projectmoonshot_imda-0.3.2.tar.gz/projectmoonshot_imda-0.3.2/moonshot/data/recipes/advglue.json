{
    "id": "advglue",
    "name": "AdvGLUE-COMBINED",
    "description": "Adversarial GLUE Benchmark (AdvGLUE) is a comprehensive robustness evaluation benchmark that focuses on the adversarial robustness evaluation of language models. It covers five natural language understanding tasks from the famous GLUE tasks and is an adversarial version of GLUE benchmark. AdvGLUE considers textual adversarial attacks from different perspectives and hierarchies, including word-level transformations, sentence-level manipulations, and human-written adversarial examples, which provide comprehensive coverage of various adversarial linguistic phenomena.",
    "tags": [
        "robustness"
    ],
    "datasets": [
        "advglue-all"
    ],
    "prompt_templates": [
    ],
    "metrics": [
        "advglue"
    ]
}