Metadata-Version: 2.1
Name: numba-dpex
Version: 0.22.1
Summary: An extension for Numba to add data-parallel offload capability
Home-page: https://github.com/IntelPython/numba-dpex
Author: Intel Corporation
License: Apache 2.0
Keywords: sycl python3 numba numpy intel mkl oneapi gpu dpcpp
Platform: Linux
Platform: Windows
Classifier: Development Status :: 4 - Beta
Classifier: Environment :: GPU
Classifier: Environment :: Plugins
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Topic :: Software Development :: Compilers
Description-Content-Type: text/markdown
License-File: LICENSE
License-File: LICENSES.third-party
Requires-Dist: numba >=0.58
Requires-Dist: dpctl
Requires-Dist: packaging
Requires-Dist: dpcpp-cpp-rt
Requires-Dist: dpcpp-llvm-spirv
Requires-Dist: dpnp



Data-parallel Extension for Numba* (numba-dpex) is a standalone extension for
the [Numba](http://numba.pydata.org) Python JIT compiler. Numba-dpex provides
a generic kernel programming API and an offload feature that extends Numba's
auto-parallelizer to generate data-parallel kernels for `parfor` nodes.

Numba-dpex's kernel API has a design and API similar to Numba's `cuda.jit`
module, but is based on the [SYCL](https://sycl.tech/) language. The
code-generation for the kernel API currently supports
[SPIR-V](https://www.khronos.org/spir/)-based
[OpenCL](https://www.khronos.org/opencl/) and
[oneAPI Level Zero](https://spec.oneapi.io/level-zero/latest/index.html)
devices that are supported by Intel&reg; DPC++ SYCL compiler runtime. Supported
devices include Intel&reg; CPUs, integrated GPUs and discrete GPUs.

The offload functionality in numba-dpex is based on Numba's `parfor`
loop-parallelizer. Our compiler extends Numba's `parfor` feature to generate
kernels and offload them to devices supported by DPC++ SYCL compiler runtime.
The offload functionality is supported via a new NumPy drop-in replacement
library: [dpnp](https://github.com/IntelPython/dpnp). Note that `dpnp` and NumPy-based
expressions can be used together in the same function, with `dpnp` expressions getting
offloaded by `numba-dpex` and NumPy expressions getting parallelized by Numba.
