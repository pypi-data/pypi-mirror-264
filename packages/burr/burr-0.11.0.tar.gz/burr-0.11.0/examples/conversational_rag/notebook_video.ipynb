{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9ee260-e582-4ca6-b688-7be184f1d986",
   "metadata": {},
   "source": [
    "# Conversational RAG Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T20:47:37.515883Z",
     "start_time": "2024-03-26T20:47:35.314767Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import pprint\n",
    "from typing import Tuple\n",
    "from hamilton import dataflows, driver\n",
    "import burr.core\n",
    "from burr.core import ApplicationBuilder, State, default, expr\n",
    "from burr.core.action import action\n",
    "from application import PrintStepHook # local import from application.py\n",
    "from burr.tracking import LocalTrackingClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1d578469a918b1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Load your \"chain\" or conversational RAG \"pipeline\"\n",
    "\n",
    "We use Hamilton here. But you could use LangChain, etc., or forgo them and write your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6a018aff1154f0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T20:47:42.057246Z",
     "start_time": "2024-03-26T20:47:40.500075Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1051pt\" height=\"303pt\"\n",
       " viewBox=\"0.00 0.00 1050.60 302.80\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 298.8)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-298.8 1046.6,-298.8 1046.6,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster__legend</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"19.38,-156.8 19.38,-286.8 104.23,-286.8 104.23,-156.8 19.38,-156.8\"/>\n",
       "<text text-anchor=\"middle\" x=\"61.8\" y=\"-269.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Legend</text>\n",
       "</g>\n",
       "<!-- answer_prompt -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>answer_prompt</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M788.75,-123.6C788.75,-123.6 689.15,-123.6 689.15,-123.6 683.15,-123.6 677.15,-117.6 677.15,-111.6 677.15,-111.6 677.15,-72 677.15,-72 677.15,-66 683.15,-60 689.15,-60 689.15,-60 788.75,-60 788.75,-60 794.75,-60 800.75,-66 800.75,-72 800.75,-72 800.75,-111.6 800.75,-111.6 800.75,-117.6 794.75,-123.6 788.75,-123.6\"/>\n",
       "<text text-anchor=\"start\" x=\"687.95\" y=\"-100.5\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">answer_prompt</text>\n",
       "<text text-anchor=\"start\" x=\"731.45\" y=\"-72.5\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">str</text>\n",
       "</g>\n",
       "<!-- conversational_rag_response -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>conversational_rag_response</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M1030.6,-93.6C1030.6,-93.6 841.75,-93.6 841.75,-93.6 835.75,-93.6 829.75,-87.6 829.75,-81.6 829.75,-81.6 829.75,-42 829.75,-42 829.75,-36 835.75,-30 841.75,-30 841.75,-30 1030.6,-30 1030.6,-30 1036.6,-30 1042.6,-36 1042.6,-42 1042.6,-42 1042.6,-81.6 1042.6,-81.6 1042.6,-87.6 1036.6,-93.6 1030.6,-93.6\"/>\n",
       "<text text-anchor=\"start\" x=\"840.55\" y=\"-70.5\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">conversational_rag_response</text>\n",
       "<text text-anchor=\"start\" x=\"928.68\" y=\"-42.5\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">str</text>\n",
       "</g>\n",
       "<!-- answer_prompt&#45;&gt;conversational_rag_response -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>answer_prompt&#45;&gt;conversational_rag_response</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M801.18,-82.39C806.7,-81.54 812.4,-80.67 818.2,-79.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"818.59,-83.26 827.94,-78.28 817.53,-76.34 818.59,-83.26\"/>\n",
       "</g>\n",
       "<!-- standalone_question_prompt -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>standalone_question_prompt</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M351.95,-145.6C351.95,-145.6 164.6,-145.6 164.6,-145.6 158.6,-145.6 152.6,-139.6 152.6,-133.6 152.6,-133.6 152.6,-94 152.6,-94 152.6,-88 158.6,-82 164.6,-82 164.6,-82 351.95,-82 351.95,-82 357.95,-82 363.95,-88 363.95,-94 363.95,-94 363.95,-133.6 363.95,-133.6 363.95,-139.6 357.95,-145.6 351.95,-145.6\"/>\n",
       "<text text-anchor=\"start\" x=\"163.4\" y=\"-122.5\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">standalone_question_prompt</text>\n",
       "<text text-anchor=\"start\" x=\"250.78\" y=\"-94.5\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">str</text>\n",
       "</g>\n",
       "<!-- standalone_question -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>standalone_question</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M537.55,-123.6C537.55,-123.6 404.95,-123.6 404.95,-123.6 398.95,-123.6 392.95,-117.6 392.95,-111.6 392.95,-111.6 392.95,-72 392.95,-72 392.95,-66 398.95,-60 404.95,-60 404.95,-60 537.55,-60 537.55,-60 543.55,-60 549.55,-66 549.55,-72 549.55,-72 549.55,-111.6 549.55,-111.6 549.55,-117.6 543.55,-123.6 537.55,-123.6\"/>\n",
       "<text text-anchor=\"start\" x=\"403.75\" y=\"-100.5\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">standalone_question</text>\n",
       "<text text-anchor=\"start\" x=\"463.75\" y=\"-72.5\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">str</text>\n",
       "</g>\n",
       "<!-- standalone_question_prompt&#45;&gt;standalone_question -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>standalone_question_prompt&#45;&gt;standalone_question</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M364.14,-102.86C370.01,-102.25 375.87,-101.64 381.66,-101.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"381.61,-104.56 391.19,-100.04 380.88,-97.6 381.61,-104.56\"/>\n",
       "</g>\n",
       "<!-- context -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>context</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M636.15,-189.6C636.15,-189.6 590.55,-189.6 590.55,-189.6 584.55,-189.6 578.55,-183.6 578.55,-177.6 578.55,-177.6 578.55,-138 578.55,-138 578.55,-132 584.55,-126 590.55,-126 590.55,-126 636.15,-126 636.15,-126 642.15,-126 648.15,-132 648.15,-138 648.15,-138 648.15,-177.6 648.15,-177.6 648.15,-183.6 642.15,-189.6 636.15,-189.6\"/>\n",
       "<text text-anchor=\"start\" x=\"589.35\" y=\"-166.5\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">context</text>\n",
       "<text text-anchor=\"start\" x=\"605.85\" y=\"-138.5\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">str</text>\n",
       "</g>\n",
       "<!-- context&#45;&gt;answer_prompt -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>context&#45;&gt;answer_prompt</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M648.45,-139.59C654.6,-136.31 661.2,-132.78 667.94,-129.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"669.36,-132.39 676.53,-124.59 666.06,-126.22 669.36,-132.39\"/>\n",
       "</g>\n",
       "<!-- standalone_question&#45;&gt;answer_prompt -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>standalone_question&#45;&gt;answer_prompt</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M549.82,-91.8C586.3,-91.8 629.57,-91.8 665.4,-91.8\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"665.24,-95.3 675.24,-91.8 665.24,-88.3 665.24,-95.3\"/>\n",
       "</g>\n",
       "<!-- standalone_question&#45;&gt;context -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>standalone_question&#45;&gt;context</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M540.66,-124.03C549.94,-128.4 559.26,-132.79 567.97,-136.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"566.34,-139.99 576.88,-141.09 569.32,-133.66 566.34,-139.99\"/>\n",
       "</g>\n",
       "<!-- vector_store -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>vector_store</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M533.05,-267.6C533.05,-267.6 409.45,-267.6 409.45,-267.6 403.45,-267.6 397.45,-261.6 397.45,-255.6 397.45,-255.6 397.45,-216 397.45,-216 397.45,-210 403.45,-204 409.45,-204 409.45,-204 533.05,-204 533.05,-204 539.05,-204 545.05,-210 545.05,-216 545.05,-216 545.05,-255.6 545.05,-255.6 545.05,-261.6 539.05,-267.6 533.05,-267.6\"/>\n",
       "<text text-anchor=\"start\" x=\"430.75\" y=\"-244.5\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">vector_store</text>\n",
       "<text text-anchor=\"start\" x=\"408.25\" y=\"-216.5\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">VectorStoreRetriever</text>\n",
       "</g>\n",
       "<!-- vector_store&#45;&gt;context -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>vector_store&#45;&gt;context</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M533.57,-203.6C538.99,-200.66 544.38,-197.69 549.55,-194.8 555.71,-191.35 562.17,-187.65 568.5,-183.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"570.12,-187.08 576.98,-179.01 566.58,-181.04 570.12,-187.08\"/>\n",
       "</g>\n",
       "<!-- llm_client -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>llm_client</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M288.58,-63.6C288.58,-63.6 227.98,-63.6 227.98,-63.6 221.98,-63.6 215.98,-57.6 215.98,-51.6 215.98,-51.6 215.98,-12 215.98,-12 215.98,-6 221.98,0 227.98,0 227.98,0 288.58,0 288.58,0 294.58,0 300.58,-6 300.58,-12 300.58,-12 300.58,-51.6 300.58,-51.6 300.58,-57.6 294.58,-63.6 288.58,-63.6\"/>\n",
       "<text text-anchor=\"start\" x=\"226.78\" y=\"-40.5\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">llm_client</text>\n",
       "<text text-anchor=\"start\" x=\"235.03\" y=\"-12.5\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">OpenAI</text>\n",
       "</g>\n",
       "<!-- llm_client&#45;&gt;standalone_question -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>llm_client&#45;&gt;standalone_question</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M300.96,-43.65C324.07,-50.23 353.72,-58.66 381.74,-66.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"380.76,-69.99 391.33,-69.36 382.67,-63.25 380.76,-69.99\"/>\n",
       "</g>\n",
       "<!-- llm_client&#45;&gt;conversational_rag_response -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>llm_client&#45;&gt;conversational_rag_response</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M300.74,-32.6C391.46,-34.48 614.35,-39.91 800.75,-50.8 806.45,-51.13 812.28,-51.5 818.17,-51.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"817.81,-55.38 828.03,-52.58 818.3,-48.4 817.81,-55.38\"/>\n",
       "</g>\n",
       "<!-- _standalone_question_prompt_inputs -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>_standalone_question_prompt_inputs</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"123.6,-146.6 0,-146.6 0,-81 123.6,-81 123.6,-146.6\"/>\n",
       "<text text-anchor=\"start\" x=\"25.3\" y=\"-118.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">question</text>\n",
       "<text text-anchor=\"start\" x=\"93.3\" y=\"-118.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">str</text>\n",
       "<text text-anchor=\"start\" x=\"14.43\" y=\"-97.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">chat_history</text>\n",
       "<text text-anchor=\"start\" x=\"92.55\" y=\"-97.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">list</text>\n",
       "</g>\n",
       "<!-- _standalone_question_prompt_inputs&#45;&gt;standalone_question_prompt -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>_standalone_question_prompt_inputs&#45;&gt;standalone_question_prompt</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M124.07,-113.8C129.56,-113.8 135.24,-113.8 141,-113.8\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"140.67,-117.3 150.67,-113.8 140.67,-110.3 140.67,-117.3\"/>\n",
       "</g>\n",
       "<!-- _context_inputs -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>_context_inputs</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"512.68,-186.1 429.83,-186.1 429.83,-141.5 512.68,-141.5 512.68,-186.1\"/>\n",
       "<text text-anchor=\"start\" x=\"444.63\" y=\"-158\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">top_k</text>\n",
       "<text text-anchor=\"start\" x=\"483.63\" y=\"-158\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">int</text>\n",
       "</g>\n",
       "<!-- _context_inputs&#45;&gt;context -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>_context_inputs&#45;&gt;context</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M513.15,-162.05C530.11,-161.32 549.85,-160.48 567.23,-159.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"566.9,-163.25 576.74,-159.32 566.6,-156.26 566.9,-163.25\"/>\n",
       "</g>\n",
       "<!-- _vector_store_inputs -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>_vector_store_inputs</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"316.95,-258.1 199.6,-258.1 199.6,-213.5 316.95,-213.5 316.95,-258.1\"/>\n",
       "<text text-anchor=\"start\" x=\"214.4\" y=\"-230\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">input_texts</text>\n",
       "<text text-anchor=\"start\" x=\"285.65\" y=\"-230\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">list</text>\n",
       "</g>\n",
       "<!-- _vector_store_inputs&#45;&gt;vector_store -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>_vector_store_inputs&#45;&gt;vector_store</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M317.2,-235.8C338.28,-235.8 362.57,-235.8 385.49,-235.8\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"385.46,-239.3 395.46,-235.8 385.46,-232.3 385.46,-239.3\"/>\n",
       "</g>\n",
       "<!-- input -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>input</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"88.8,-256.1 34.8,-256.1 34.8,-219.5 88.8,-219.5 88.8,-256.1\"/>\n",
       "<text text-anchor=\"middle\" x=\"61.8\" y=\"-232\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">input</text>\n",
       "</g>\n",
       "<!-- function -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>function</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M84.23,-201.1C84.23,-201.1 39.38,-201.1 39.38,-201.1 33.38,-201.1 27.38,-195.1 27.38,-189.1 27.38,-189.1 27.38,-176.5 27.38,-176.5 27.38,-170.5 33.38,-164.5 39.38,-164.5 39.38,-164.5 84.23,-164.5 84.23,-164.5 90.23,-164.5 96.23,-170.5 96.23,-176.5 96.23,-176.5 96.23,-189.1 96.23,-189.1 96.23,-195.1 90.23,-201.1 84.23,-201.1\"/>\n",
       "<text text-anchor=\"middle\" x=\"61.8\" y=\"-177\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">function</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x12ad04df0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads Hamilton DAG\n",
    "conversational_rag = dataflows.import_module(\"conversational_rag\")\n",
    "conversational_rag_driver = (\n",
    "    driver.Builder()\n",
    "    .with_config({})  # replace with configuration as appropriate\n",
    "    .with_modules(conversational_rag)\n",
    "    .build()\n",
    ")\n",
    "conversational_rag_driver.display_all_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b3515afd2de6e4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Create the actions that will constitute our application\n",
    "\n",
    "We will use the functional (vs class) approach to declaring actions here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6433dad5abc6eb16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T20:47:42.065785Z",
     "start_time": "2024-03-26T20:47:42.059539Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@action(\n",
    "    reads=[\"question\", \"chat_history\"],\n",
    "    writes=[\"chat_history\"],\n",
    ")\n",
    "def ai_converse(state: State, vector_store: object) -> Tuple[dict, State]:\n",
    "    \"\"\"AI conversing step. Uses Hamilton to execute the conversational pipeline.\"\"\"\n",
    "    result = conversational_rag_driver.execute(\n",
    "        [\"conversational_rag_response\"],\n",
    "        inputs={\n",
    "            \"question\": state[\"question\"],\n",
    "            \"chat_history\": state[\"chat_history\"],\n",
    "        },\n",
    "        # we use overrides here because we want to pass in the vector store\n",
    "        overrides={\n",
    "            \"vector_store\": vector_store,\n",
    "        }\n",
    "    )\n",
    "    new_history = f\"AI: {result['conversational_rag_response']}\"\n",
    "    return result, state.append(chat_history=new_history)\n",
    "\n",
    "\n",
    "@action(\n",
    "    reads=[],\n",
    "    writes=[\"question\", \"chat_history\"],\n",
    ")\n",
    "def human_converse(state: State, user_question: str) -> Tuple[dict, State]:\n",
    "    \"\"\"Human converse step -- make sure we get input, and store it as state.\"\"\"\n",
    "    state = state.update(question=user_question).append(chat_history=f\"Human: {user_question}\")\n",
    "    return {\"question\": user_question}, state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9579b47aac2c53a0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Create the application\n",
    "\n",
    "We now create the application, which is a collection of actions, and then set the transitions between the actions based on values in State.\n",
    "\n",
    "We also intialize initial values etc to populate the application with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77e9f67b660a0953",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T20:50:25.642660Z",
     "start_time": "2024-03-26T20:50:25.616245Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# what we will do RAG over.\n",
    "initial_documents = [\n",
    "    \"harrison worked at kensho\",\n",
    "    \"stefan worked at Stitch Fix\",\n",
    "    \"stefan likes tacos\",\n",
    "    \"elijah worked at TwoSigma\",\n",
    "    \"elijah likes mango\",\n",
    "    \"stefan used to work at IBM\",\n",
    "    \"elijah likes to go biking\",\n",
    "    \"stefan likes to bake sourdough\",\n",
    "]\n",
    "# bootstrap the vector store;\n",
    "vector_store = conversational_rag_driver.execute(\n",
    "    [\"vector_store\"],\n",
    "    inputs={\"input_texts\": initial_documents})[\"vector_store\"]\n",
    "# what we will initialize the application with\n",
    "initial_state = {\n",
    "    \"question\": \"\",\n",
    "    \"chat_history\": [],\n",
    "}\n",
    "import uuid\n",
    "app_id = str(uuid.uuid4())\n",
    "app = (\n",
    "    ApplicationBuilder()\n",
    "    # add the actions\n",
    "    .with_actions(\n",
    "        # bind the vector store to the AI conversational step\n",
    "        ai_converse=ai_converse.bind(vector_store=vector_store),\n",
    "        human_converse=human_converse,\n",
    "        terminal=burr.core.Result(\"chat_history\"),\n",
    "    )\n",
    "    # set the transitions between actions\n",
    "    .with_transitions(\n",
    "        (\"ai_converse\", \"human_converse\", default),\n",
    "        (\"human_converse\", \"terminal\", expr(\"'exit' in question\")),\n",
    "        (\"human_converse\", \"ai_converse\", default),\n",
    "    )\n",
    "    # add identifiers that will help track the application\n",
    "    .with_identifiers(app_id=app_id, partition_key=\"sample_user\")\n",
    "    # initialize the state\n",
    "    .with_state(**initial_state)\n",
    "    # say what the initial action is\n",
    "    .with_entrypoint(\"human_converse\")\n",
    "    # add a hook to print the steps -- optional but shows that Burr is pluggable\n",
    "    .with_hooks(PrintStepHook())\n",
    "    # add tracking -- this will show up in the BURR UI.\n",
    "    .with_tracker(project=\"demo:conversational-rag\")\n",
    "    # build the application\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf5d1e084a791fa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T20:48:39.379712Z",
     "start_time": "2024-03-26T20:48:38.701659Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"292pt\" height=\"194pt\"\n",
       " viewBox=\"0.00 0.00 292.28 193.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 189.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-189.5 288.28,-189.5 288.28,4 -4,4\"/>\n",
       "<!-- ai_converse -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>ai_converse</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M82.38,-185.5C82.38,-185.5 25.88,-185.5 25.88,-185.5 19.88,-185.5 13.88,-179.5 13.88,-173.5 13.88,-173.5 13.88,-161.5 13.88,-161.5 13.88,-155.5 19.88,-149.5 25.88,-149.5 25.88,-149.5 82.38,-149.5 82.38,-149.5 88.38,-149.5 94.38,-155.5 94.38,-161.5 94.38,-161.5 94.38,-173.5 94.38,-173.5 94.38,-179.5 88.38,-185.5 82.38,-185.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"54.12\" y=\"-162.45\" font-family=\"Times,serif\" font-size=\"14.00\">ai_converse</text>\n",
       "</g>\n",
       "<!-- human_converse -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>human_converse</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M96.25,-118.5C96.25,-118.5 12,-118.5 12,-118.5 6,-118.5 0,-112.5 0,-106.5 0,-106.5 0,-94.5 0,-94.5 0,-88.5 6,-82.5 12,-82.5 12,-82.5 96.25,-82.5 96.25,-82.5 102.25,-82.5 108.25,-88.5 108.25,-94.5 108.25,-94.5 108.25,-106.5 108.25,-106.5 108.25,-112.5 102.25,-118.5 96.25,-118.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"54.12\" y=\"-95.45\" font-family=\"Times,serif\" font-size=\"14.00\">human_converse</text>\n",
       "</g>\n",
       "<!-- ai_converse&#45;&gt;human_converse -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>ai_converse&#45;&gt;human_converse</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M48.07,-149.08C47.49,-143.25 47.27,-136.59 47.42,-130.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"50.89,-130.66 47.98,-120.48 43.9,-130.26 50.89,-130.66\"/>\n",
       "</g>\n",
       "<!-- human_converse&#45;&gt;ai_converse -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>human_converse&#45;&gt;ai_converse</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M60.19,-118.97C60.76,-124.8 60.98,-131.46 60.83,-137.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"57.36,-137.38 60.27,-147.57 64.34,-137.79 57.36,-137.38\"/>\n",
       "</g>\n",
       "<!-- terminal -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>terminal</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M73,-36C73,-36 35.25,-36 35.25,-36 29.25,-36 23.25,-30 23.25,-24 23.25,-24 23.25,-12 23.25,-12 23.25,-6 29.25,0 35.25,0 35.25,0 73,0 73,0 79,0 85,-6 85,-12 85,-12 85,-24 85,-24 85,-30 79,-36 73,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"54.12\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">terminal</text>\n",
       "</g>\n",
       "<!-- human_converse&#45;&gt;terminal -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>human_converse&#45;&gt;terminal</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M54.12,-82.03C54.12,-72.01 54.12,-59.18 54.12,-47.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"57.63,-47.95 54.13,-37.95 50.63,-47.95 57.63,-47.95\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.38\" y=\"-54.2\" font-family=\"Times,serif\" font-size=\"14.00\">&#39;exit&#39; in question</text>\n",
       "</g>\n",
       "<!-- input__user_question -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>input__user_question</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"198.12\" cy=\"-167.5\" rx=\"86.15\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"198.12\" y=\"-162.45\" font-family=\"Times,serif\" font-size=\"14.00\">input: user_question</text>\n",
       "</g>\n",
       "<!-- input__user_question&#45;&gt;human_converse -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>input__user_question&#45;&gt;human_converse</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M162.9,-150.6C144.9,-142.48 122.71,-132.46 103.08,-123.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"104.72,-120.5 94.16,-119.57 101.84,-126.88 104.72,-120.5\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x12aabd120>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's visualize what we have\n",
    "app.visualize(include_conditions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430bab287b6ad9a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Let's run the app. \n",
    "\n",
    "Let's run it a step at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bcfe9ca48f87618",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T20:50:38.782857Z",
     "start_time": "2024-03-26T20:50:28.797204Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask something (or type exit to quit):  who is Stefan? Answer in English.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥Processing input from user...\n",
      "üéôüí¨ who is Stefan? Answer in English. \n",
      "\n",
      "Ran action human_converse with result:\n",
      " {'question': 'who is Stefan? Answer in English.'} \n",
      " and state:\n",
      " {'__PRIOR_STEP': 'human_converse',\n",
      " '__SEQUENCE_ID': 0,\n",
      " 'chat_history': ['Human: who is Stefan? Answer in English.'],\n",
      " 'question': 'who is Stefan? Answer in English.'}\n"
     ]
    }
   ],
   "source": [
    "app.reset_to_entrypoint() # reset the app to the entrypoint\n",
    "user_question = input(\"Ask something (or type exit to quit): \")\n",
    "previous_action, result, state = app.step(\n",
    "    inputs={\"user_question\": user_question},\n",
    ")\n",
    "print(f\"Ran action {previous_action.name} with result:\\n {pprint.pformat(result)} \\n and state:\\n {pprint.pformat(state.get_all())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81940578d58fd602",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T20:50:44.662755Z",
     "start_time": "2024-03-26T20:50:41.919782Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§î AI is thinking...\n",
      "ü§ñüí¨ Stefan is a person who used to work at IBM, now works at Stitch Fix, likes tacos, and likes to bake sourdough. \n",
      "\n",
      "Ran action ai_converse with result:\n",
      " {'conversational_rag_response': 'Stefan is a person who used to work at IBM, '\n",
      "                                'now works at Stitch Fix, likes tacos, and '\n",
      "                                'likes to bake sourdough.'} \n",
      " and state:\n",
      " {'__PRIOR_STEP': 'ai_converse',\n",
      " '__SEQUENCE_ID': 1,\n",
      " 'chat_history': ['Human: who is Stefan? Answer in English.',\n",
      "                  'AI: Stefan is a person who used to work at IBM, now works '\n",
      "                  'at Stitch Fix, likes tacos, and likes to bake sourdough.'],\n",
      " 'question': 'who is Stefan? Answer in English.'}\n"
     ]
    }
   ],
   "source": [
    "# now let's run the AI conversational step\n",
    "previous_action, result, state = app.step()\n",
    "print(f\"Ran action {previous_action.name} with result:\\n {pprint.pformat(result)} \\n and state:\\n {pprint.pformat(state.get_all())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec2f4908c2dde2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Let's now run the app to completion\n",
    "\n",
    "You could do the above for each action. Or you could tell the app to run until certain\n",
    "actions/conditions are met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be6c573158b65cb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T20:52:21.364028Z",
     "start_time": "2024-03-26T20:50:52.382808Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RAG with initial state:\n",
      " {'__PRIOR_STEP': 'ai_converse',\n",
      " '__SEQUENCE_ID': 1,\n",
      " 'chat_history': ['Human: who is Stefan? Answer in English.',\n",
      "                  'AI: Stefan is a person who used to work at IBM, now works '\n",
      "                  'at Stitch Fix, likes tacos, and likes to bake sourdough.'],\n",
      " 'question': 'who is Stefan? Answer in English.'}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask something (or type exit to quit):  Where does Elijah work?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥Processing input from user...\n",
      "üéôüí¨ Where does Elijah work? \n",
      "\n",
      "ü§î AI is thinking...\n",
      "ü§ñüí¨ False \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask something (or type exit to quit):  What is his favorite food?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥Processing input from user...\n",
      "üéôüí¨ What is his favorite food? \n",
      "\n",
      "ü§î AI is thinking...\n",
      "ü§ñüí¨ Mango \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask something (or type exit to quit):  Who would be the best person for financial advice?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥Processing input from user...\n",
      "üéôüí¨ Who would be the best person for financial advice? \n",
      "\n",
      "ü§î AI is thinking...\n",
      "ü§ñüí¨ Elijah from TwoSigma would be the best person to provide financial advice. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask something (or type exit to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥Processing input from user...\n",
      "üéôüí¨ exit \n",
      "\n",
      "{'chat_history': ['Human: who is Stefan? Answer in English.',\n",
      "                  'AI: Stefan is a person who used to work at IBM, now works '\n",
      "                  'at Stitch Fix, likes tacos, and likes to bake sourdough.',\n",
      "                  'Human: Where does Elijah work?',\n",
      "                  'AI: False',\n",
      "                  'Human: What is his favorite food?',\n",
      "                  'AI: Mango',\n",
      "                  'Human: Who would be the best person for financial advice?',\n",
      "                  'AI: Elijah from TwoSigma would be the best person to '\n",
      "                  'provide financial advice.',\n",
      "                  'Human: exit']}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running RAG with initial state:\\n {pprint.pformat(app.state.get_all())}\")\n",
    "while True:\n",
    "    user_question = input(\"Ask something (or type exit to quit): \")\n",
    "    previous_action, result, state = app.run(\n",
    "        halt_before=[\"human_converse\"],\n",
    "        halt_after=[\"terminal\"],\n",
    "        inputs={\"user_question\": user_question},\n",
    "    )\n",
    "    if previous_action.name == \"terminal\":\n",
    "        # reached the end\n",
    "        pprint.pprint(result)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169946a65f977df9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Reloading from prior state\n",
    "\n",
    "Burr makes it easy to reload from a prior state. In this example we'll just use what is logged to the tracker to \"go back in time\" and reload the application to that state. \n",
    "\n",
    "This is useful for debugging, building the application itself, etc.\n",
    "\n",
    "There are two ways to load prior state:\n",
    "1. Load the state outside the Burr Application. i.e. pass it in as initial state.\n",
    "2. Use the ApplicationBuilder .initialize_from() method.\n",
    "\n",
    "The difference between them, is that the first method is more flexible, allowing you to create\n",
    "new \"app_ids\", i.e. traces. The second method will keep the same app_id, and thus allow you \n",
    "\"pick up where you left off\", e.g. in the case of a crash, or if you wanted to start from \n",
    "the last conversation with a user.\n",
    "\n",
    "Below we show how to do the first method. Then after that the second method, to show how\n",
    "to pick up the prior conversation from where it left off.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8539b794-fc25-4ab1-a85c-c12877d0a6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'737ea72d-1df8-4114-b698-a824dbcf2633'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7f4dd64f73ed2d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T20:52:37.419848Z",
     "start_time": "2024-03-26T20:52:37.393869Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded state from app_id:737ea72d-1df8-4114-b698-a824dbcf2633, sequence_id:7::\n",
      " {'__SEQUENCE_ID': 7,\n",
      " 'chat_history': ['Human: who is Stefan? Answer in English.',\n",
      "                  'AI: Stefan is a person who used to work at IBM, now works '\n",
      "                  'at Stitch Fix, likes tacos, and likes to bake sourdough.',\n",
      "                  'Human: Where does Elijah work?',\n",
      "                  'AI: False',\n",
      "                  'Human: What is his favorite food?',\n",
      "                  'AI: Mango',\n",
      "                  'Human: Who would be the best person for financial advice?',\n",
      "                  'AI: Elijah from TwoSigma would be the best person to '\n",
      "                  'provide financial advice.'],\n",
      " 'question': 'Who would be the best person for financial advice?'}\n"
     ]
    }
   ],
   "source": [
    "# set up for rewinding to a prior state -- loading it in as initial state\n",
    "prior_app_id = app_id\n",
    "last_sequence_id = app.sequence_id\n",
    "rewind_to_sequence_id = last_sequence_id - 2\n",
    "new_app_id = str(uuid.uuid4())\n",
    "\n",
    "project_name = \"demo:conversational-rag\"\n",
    "# we use the tracking client here to get the state of the application at a prior sequence_id\n",
    "tracker = LocalTrackingClient(project=project_name)\n",
    "persisted_state = tracker.load(partition_key=\"sample_user\", \n",
    "                               app_id=prior_app_id, \n",
    "                               sequence_id=rewind_to_sequence_id)\n",
    "state_values = persisted_state['state'].get_all()\n",
    "print(f\"Loaded state from app_id:{prior_app_id}, \"\n",
    "      f\"sequence_id:{rewind_to_sequence_id}::\\n \"\n",
    "      f\"{pprint.pformat(state_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ee618e3-15c0-403b-bc96-3a2faaea457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_app = (\n",
    "    ApplicationBuilder()\n",
    "    # add the actions\n",
    "    .with_actions(\n",
    "        # bind the vector store to the AI conversational step\n",
    "        ai_converse=ai_converse.bind(vector_store=vector_store),\n",
    "        human_converse=human_converse,\n",
    "        terminal=burr.core.Result(\"chat_history\"),\n",
    "    )\n",
    "    # set the transitions between actions\n",
    "    .with_transitions(\n",
    "        (\"ai_converse\", \"human_converse\", default),\n",
    "        (\"human_converse\", \"terminal\", expr(\"'exit' in question\")),\n",
    "        (\"human_converse\", \"ai_converse\", default),\n",
    "    )\n",
    "    # add identifiers that will help track the application\n",
    "    .with_identifiers(app_id=new_app_id, partition_key=\"sample_user\")\n",
    "    # set state to prior state\n",
    "    .with_state(**persisted_state[\"state\"].get_all())\n",
    "    # say where we want to start\n",
    "    .with_entrypoint(\"human_converse\")\n",
    "    # add a hook to print the steps -- optional but shows that Burr is pluggable\n",
    "    .with_hooks(PrintStepHook())\n",
    "    # add tracking -- this will show up in the BURR UI.\n",
    "    .with_tracker(tracker)\n",
    "    # build the application\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34140c5864b940dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T20:54:24.035153Z",
     "start_time": "2024-03-26T20:53:19.237522Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RAG with loaded state:\n",
      " {'__SEQUENCE_ID': 7,\n",
      " 'chat_history': ['Human: who is Stefan? Answer in English.',\n",
      "                  'AI: Stefan is a person who used to work at IBM, now works '\n",
      "                  'at Stitch Fix, likes tacos, and likes to bake sourdough.',\n",
      "                  'Human: Where does Elijah work?',\n",
      "                  'AI: False',\n",
      "                  'Human: What is his favorite food?',\n",
      "                  'AI: Mango',\n",
      "                  'Human: Who would be the best person for financial advice?',\n",
      "                  'AI: Elijah from TwoSigma would be the best person to '\n",
      "                  'provide financial advice.'],\n",
      " 'question': 'Who would be the best person for financial advice?'}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask something (or type exit to quit):  What should I get him for Christmas?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥Processing input from user...\n",
      "üéôüí¨ What should I get him for Christmas? \n",
      "\n",
      "ü§î AI is thinking...\n",
      "ü§ñüí¨ You could consider getting Elijah a new biking accessory, some mango-related gift, or something related to his work at TwoSigma. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask something (or type exit to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥Processing input from user...\n",
      "üéôüí¨ exit \n",
      "\n",
      "{'chat_history': ['Human: who is Stefan? Answer in English.',\n",
      "                  'AI: Stefan is a person who used to work at IBM, now works '\n",
      "                  'at Stitch Fix, likes tacos, and likes to bake sourdough.',\n",
      "                  'Human: Where does Elijah work?',\n",
      "                  'AI: False',\n",
      "                  'Human: What is his favorite food?',\n",
      "                  'AI: Mango',\n",
      "                  'Human: Who would be the best person for financial advice?',\n",
      "                  'AI: Elijah from TwoSigma would be the best person to '\n",
      "                  'provide financial advice.',\n",
      "                  'Human: What should I get him for Christmas?',\n",
      "                  'AI: You could consider getting Elijah a new biking '\n",
      "                  'accessory, some mango-related gift, or something related to '\n",
      "                  'his work at TwoSigma.',\n",
      "                  'Human: exit']}\n"
     ]
    }
   ],
   "source": [
    "# We can now change test, debug, etc. from this prior state.\n",
    "print(f\"Running RAG with loaded state:\\n {pprint.pformat(state_values)}\")\n",
    "while True:\n",
    "    user_question = input(\"Ask something (or type exit to quit): \")\n",
    "    previous_action, result, state = other_app.run(\n",
    "        halt_before=[\"human_converse\"],\n",
    "        halt_after=[\"terminal\"],\n",
    "        inputs={\"user_question\": user_question},\n",
    "    )\n",
    "    if previous_action and previous_action.name == \"terminal\":\n",
    "        # reached the end\n",
    "        pprint.pprint(result)\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc62a033644c7b80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T21:04:56.748649Z",
     "start_time": "2024-03-26T21:04:56.742019Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Now let's show how to use the ApplicationBuilder.initialize_from() method to pick up where we left off.\n",
    "# This is useful if you want to continue a conversation with a user, or if you had a crash, etc.\n",
    "\n",
    "# set up for rewinding to a prior state -- loading it in as initial state\n",
    "prior_app_id = app_id\n",
    "new_app_id = str(uuid.uuid4())\n",
    "\n",
    "project_name = \"demo:conversational-rag\"\n",
    "# we use the tracking client here to get the state of the application at a prior sequence_id\n",
    "tracker = LocalTrackingClient(project=project_name)\n",
    "pick_up_where_we_left_off_app = (\n",
    "    ApplicationBuilder()\n",
    "    # add the actions\n",
    "    .with_actions(\n",
    "        # bind the vector store to the AI conversational step\n",
    "        ai_converse=ai_converse.bind(vector_store=vector_store),\n",
    "        human_converse=human_converse,\n",
    "        terminal=burr.core.Result(\"chat_history\"),\n",
    "    )\n",
    "    # set the transitions between actions\n",
    "    .with_transitions(\n",
    "        (\"ai_converse\", \"human_converse\", default),\n",
    "        (\"human_converse\", \"terminal\", expr(\"'exit' in question\")),\n",
    "        (\"human_converse\", \"ai_converse\", default),\n",
    "    )\n",
    "    # add identifiers that will help track the application\n",
    "    .with_identifiers(app_id=prior_app_id, partition_key=\"sample_user\")\n",
    "    .initialize_from(\n",
    "        initializer=tracker,\n",
    "        resume_at_next_action=False, # we want to always start at human_converse; our entrypoint\n",
    "        default_entrypoint=\"human_converse\",\n",
    "        default_state=initial_state, # set some default state incase we can't find the prior state\n",
    "    )\n",
    "    # add a hook to print the steps -- optional but shows that Burr is pluggable\n",
    "    .with_hooks(PrintStepHook())\n",
    "    # add tracking -- this will show up in the BURR UI.\n",
    "    .with_tracker(tracker)\n",
    "    # build the application\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6d23d6d6a6643d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T21:05:41.246005Z",
     "start_time": "2024-03-26T21:05:02.855430Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RAG with loaded state:\n",
      " {'__PRIOR_STEP': 'terminal',\n",
      " '__SEQUENCE_ID': 9,\n",
      " 'chat_history': ['Human: who is Stefan? Answer in English.',\n",
      "                  'AI: Stefan is a person who used to work at IBM, now works '\n",
      "                  'at Stitch Fix, likes tacos, and likes to bake sourdough.',\n",
      "                  'Human: Where does Elijah work?',\n",
      "                  'AI: False',\n",
      "                  'Human: What is his favorite food?',\n",
      "                  'AI: Mango',\n",
      "                  'Human: Who would be the best person for financial advice?',\n",
      "                  'AI: Elijah from TwoSigma would be the best person to '\n",
      "                  'provide financial advice.',\n",
      "                  'Human: exit'],\n",
      " 'question': 'exit'}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask something (or type exit to quit):  Who should I take to a Mexican restaurant?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥Processing input from user...\n",
      "üéôüí¨ Who should I take to a Mexican restaurant? \n",
      "\n",
      "ü§î AI is thinking...\n",
      "ü§ñüí¨ Stefan \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask something (or type exit to quit):  Why is that?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥Processing input from user...\n",
      "üéôüí¨ Why is that? \n",
      "\n",
      "ü§î AI is thinking...\n",
      "ü§ñüí¨ You should take Stefan to a Mexican restaurant because he likes tacos. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask something (or type exit to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥Processing input from user...\n",
      "üéôüí¨ exit \n",
      "\n",
      "{'chat_history': ['Human: who is Stefan? Answer in English.',\n",
      "                  'AI: Stefan is a person who used to work at IBM, now works '\n",
      "                  'at Stitch Fix, likes tacos, and likes to bake sourdough.',\n",
      "                  'Human: Where does Elijah work?',\n",
      "                  'AI: False',\n",
      "                  'Human: What is his favorite food?',\n",
      "                  'AI: Mango',\n",
      "                  'Human: Who would be the best person for financial advice?',\n",
      "                  'AI: Elijah from TwoSigma would be the best person to '\n",
      "                  'provide financial advice.',\n",
      "                  'Human: exit',\n",
      "                  'Human: Who should I take to a Mexican restaurant?',\n",
      "                  'AI: Stefan',\n",
      "                  'Human: Why is that?',\n",
      "                  'AI: You should take Stefan to a Mexican restaurant because '\n",
      "                  'he likes tacos.',\n",
      "                  'Human: exit']}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running RAG with loaded state:\\n {pprint.pformat(app.state.get_all())}\")\n",
    "while True:\n",
    "    user_question = input(\"Ask something (or type exit to quit): \")\n",
    "    previous_action, result, state = pick_up_where_we_left_off_app.run(\n",
    "        halt_before=[\"human_converse\"],\n",
    "        halt_after=[\"terminal\"],\n",
    "        inputs={\"user_question\": user_question},\n",
    "    )\n",
    "    if previous_action and previous_action.name == \"terminal\":\n",
    "        # reached the end\n",
    "        pprint.pprint(result)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe401e84026db9bb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
