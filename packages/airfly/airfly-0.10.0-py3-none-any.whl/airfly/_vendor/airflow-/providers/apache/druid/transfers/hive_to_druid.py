# Auto generated by 'inv collect-airflow'
from airfly._vendor.airflow.models.baseoperator import BaseOperator


class HiveToDruidOperator(BaseOperator):
    sql: "str"
    druid_datasource: "str"
    ts_dim: "str"
    metric_spec: "typing.Union[typing.List[typing.Any], NoneType]"
    hive_cli_conn_id: "str"
    druid_ingest_conn_id: "str"
    metastore_conn_id: "str"
    hadoop_dependency_coordinates: "typing.Union[typing.List[str], NoneType]"
    intervals: "typing.Union[typing.List[typing.Any], NoneType]"
    num_shards: "float"
    target_partition_size: "int"
    query_granularity: "str"
    segment_granularity: "str"
    hive_tblproperties: "typing.Union[typing.Dict[typing.Any, typing.Any], NoneType]"
    job_properties: "typing.Union[typing.Dict[typing.Any, typing.Any], NoneType]"
