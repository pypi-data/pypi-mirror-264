# Auto generated by 'inv collect-airflow'
from airfly._vendor.airflow.providers.apache.spark.operators.spark_submit import (
    SparkSubmitOperator,
)


class SparkJDBCOperator(SparkSubmitOperator):
    spark_app_name: "str"
    spark_conn_id: "str"
    spark_conf: "typing.Union[typing.Dict[str, typing.Any], NoneType]"
    spark_py_files: "typing.Union[str, NoneType]"
    spark_files: "typing.Union[str, NoneType]"
    spark_jars: "typing.Union[str, NoneType]"
    num_executors: "typing.Union[int, NoneType]"
    executor_cores: "typing.Union[int, NoneType]"
    executor_memory: "typing.Union[str, NoneType]"
    driver_memory: "typing.Union[str, NoneType]"
    verbose: "bool"
    principal: "typing.Union[str, NoneType]"
    keytab: "typing.Union[str, NoneType]"
    cmd_type: "str"
    jdbc_table: "typing.Union[str, NoneType]"
    jdbc_conn_id: "str"
    jdbc_driver: "typing.Union[str, NoneType]"
    metastore_table: "typing.Union[str, NoneType]"
    jdbc_truncate: "bool"
    save_mode: "typing.Union[str, NoneType]"
    save_format: "typing.Union[str, NoneType]"
    batch_size: "typing.Union[int, NoneType]"
    fetch_size: "typing.Union[int, NoneType]"
    num_partitions: "typing.Union[int, NoneType]"
    partition_column: "typing.Union[str, NoneType]"
    lower_bound: "typing.Union[str, NoneType]"
    upper_bound: "typing.Union[str, NoneType]"
    create_table_column_types: "typing.Union[str, NoneType]"
