{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff189b3b-c1f4-43fe-90bd-3276db946aca",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "Today, you would like to build a model to predict the median housing price in California.\n",
    "\n",
    "Thankfully, your coworker has prepared a few options to help you build the model.\n",
    "\n",
    "**Once you see \"CHOOSE ONE\", copy, paste, and execute one of the choices in the cell below.**\n",
    "\n",
    "You are free to run other cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba1580-2237-49cf-9464-4ea723231fd7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from joblib import dump, load\n",
    "from kishu.user_study import install_submit_cell_execution\n",
    "install_submit_cell_execution()\n",
    "\n",
    "housing = pd.read_csv(\"./housing_california.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a837dc10-2577-4e73-9a99-29ce4b4e12a9",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a726858-b53f-4dcc-81ab-0afbd32b2368",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(housing.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0339b7d5-6490-41a3-9734-948cc66a6c06",
   "metadata": {},
   "source": [
    "The median_house_value is the thing you need to predict using other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93affc96-61b3-40c3-9162-b7188c034d79",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(housing.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adf5a89-b28e-46bc-86d3-feaf878a24c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check wheather there are any missing values or null\n",
    "housing.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da09078f-30ca-4492-9b76-545b175502b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand the distribution of each feature\n",
    "housing.hist(figsize=(25,25),bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8fdfdf-0c53-4052-8c99-fdbcf67ad785",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcorr = housing.corr()\n",
    "hcorr.style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24cba50-3582-417e-87cd-f88e4fe0c072",
   "metadata": {},
   "source": [
    "# Part 1 Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb80792-6ea9-47d9-99a9-788daea62359",
   "metadata": {},
   "source": [
    "## Impute the missing values (CHOOSE ONE)\n",
    "\n",
    "Two choices to impute 207 missing values in the `total_bedrooms` column.\n",
    "\n",
    "1. **Choice 1**: Median Imputation. Simplicity is good for this dataset size.\n",
    "```python\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imputer.fit(housing.iloc[:,4:5])\n",
    "housing.iloc[:,4:5] = imputer.transform(housing.iloc[:,4:5])\n",
    "```\n",
    "2. **Choice 2**: kNN Unsupervised Learning Imputation. Median imputation can introduce bias; kNN imputer can provide a better representation.\n",
    "```python\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "housing_scaled = pd.DataFrame(scaler.fit_transform(housing), columns=housing.columns)\n",
    "\n",
    "# Apply KNN imputation\n",
    "knn_imputer = KNNImputer(n_neighbors=2)  # You can adjust the number of neighbors\n",
    "housing_imputed = pd.DataFrame(knn_imputer.fit_transform(housing_scaled), columns=housing.columns)\n",
    "\n",
    "# Inverse transform to get back to the original scale\n",
    "housing_imputed = pd.DataFrame(scaler.inverse_transform(housing_imputed), columns=housing.columns)\n",
    "\n",
    "# Replace the 4th column in the original df with the imputed values\n",
    "housing['total_bedrooms'] = housing_imputed['total_bedrooms']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e094add-e498-41fc-994a-ec9598b03f90",
   "metadata": {},
   "source": [
    "**Paste and run** the code of your choice **in the cell below**. Only edit variable names of the code snippet you choose if you need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076fed1f-9ff6-411e-a523-cf8300a7b0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22736b10-d7f6-4d96-9232-103905721681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure there is no missing value\n",
    "housing.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed26dcf-6844-47e6-819e-460470be7756",
   "metadata": {},
   "source": [
    "## Train test set split (CHOOSE ONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3617c2-4c85-4e25-af4a-2c677ace281c",
   "metadata": {},
   "source": [
    "How would you split the dataset into train and test sets?\n",
    "\n",
    "1. **Choice 1**: Random split to be fair.\n",
    "```python\n",
    "tr_data, te_data = train_test_split(housing, test_size=0.2, random_state=43)\n",
    "```\n",
    "2. **Choice 2**: Stratified split, given the correlation between columns.\n",
    "```python\n",
    "housing['income_cat'] = np.ceil(housing['median_income'] / 1.5)\n",
    "housing['income_cat'].where(housing['income_cat'] < 5, 5.0, inplace=True)\n",
    "tr_data, te_data = train_test_split(housing, test_size=0.2, stratify=housing['income_cat'])\n",
    "housing = housing.drop('income_cat',axis=1)\n",
    "tr_data = tr_data.drop('income_cat',axis=1)\n",
    "te_data = te_data.drop('income_cat',axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85802714-ec1f-40cc-8acc-2f35d453ad36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a484a7-3bca-4fb1-b8d9-cbf06634a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure splitting is successful\n",
    "print(tr_data.shape, te_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9229e6-42d4-43ed-ad8f-2169a93b2797",
   "metadata": {},
   "source": [
    "## Divide the data into feature (X) and target (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a287e7-ba2a-4e2c-8aaf-309d94618fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the training data\n",
    "X_train = tr_data.drop('median_house_value', axis=1)\n",
    "Y_train = tr_data['median_house_value']\n",
    "\n",
    "# For the testing data\n",
    "X_test = te_data.drop('median_house_value', axis=1)\n",
    "Y_test = te_data['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b5284-c0a1-4094-95b5-cd20c8d66ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that the dataset is complete\n",
    "print(X_train.head())\n",
    "print(Y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a3b050-97c2-47fa-a695-baad158cda99",
   "metadata": {},
   "source": [
    "# Part 2 Feature Engineering\n",
    "\n",
    "Several features (`total_rooms`, `total_bedrooms`, `longitude`, `latitude`) are highly correlated, let's simply drop some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf4c6d-1778-4048-ae91-3406f97ee401",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train['total_bedrooms']\n",
    "del X_test['total_bedrooms']\n",
    "del X_train['longitude']\n",
    "del X_test['longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e32a864-6237-4e93-b019-d3ed17d54701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset again.\n",
    "print(X_train.head())\n",
    "print(Y_train.head())\n",
    "print(X_test.head())\n",
    "print(Y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d3a885-5dd2-45d7-afeb-764609c0eb1a",
   "metadata": {},
   "source": [
    "# Part 3 Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd9323-b703-4347-b65c-17eb17da7312",
   "metadata": {},
   "source": [
    "## Select the model to use (CHOOSE ONE)\n",
    "\n",
    "Let's try either of the two models.\n",
    "\n",
    "1. **Choice 1**: Linear regression\n",
    "```python\n",
    "model = LinearRegression(n_jobs=-1)\n",
    "model.fit(X_train, Y_train)\n",
    "```\n",
    "2. **Choice 2**: Random Forest\n",
    "```python\n",
    "model = RandomForestRegressor(30)\n",
    "model.fit(X_train, Y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d7a2d7-1b10-43dd-956f-75ff80a37d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9fff898-69f7-45ec-9fda-c4385a11ab28",
   "metadata": {},
   "source": [
    "# Part 4 Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249078c6-564c-4050-afd7-af9ca56eb2a8",
   "metadata": {},
   "source": [
    "## Evaluate your model using RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f616fab2-1ae1-42f6-a183-8f64c2a759f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(Y_test, Y_pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4664f-496e-468e-a77f-5b7214058812",
   "metadata": {},
   "source": [
    "# Part 5: Alternative Feature Engineering\n",
    "\n",
    "Your coworker realized that \"Part 2 Feature Engineering\" should instead combine the correlated features into new features.\n",
    "\n",
    "**Try the suggestion your coworker gave. Then, report the old and new RMSE below.**\n",
    "\n",
    "**Hint**: The following code requires `X_train['longitude']`, but the column has already been dropped. You may need to restore the column.\n",
    "```python\n",
    "X_train['diag_coord'] = X_train['longitude'] + X_train['latitude']\n",
    "X_train['bedperroom'] = X_train['total_bedrooms'] / X_train['total_rooms']\n",
    "X_test['diag_coord'] = X_test['longitude'] + X_test['latitude']\n",
    "X_test['bedperroom'] = X_test['total_bedrooms'] / X_test['total_rooms']\n",
    "\n",
    "X_train = X_train.drop(['longitude', 'latitude', 'total_bedrooms', 'total_rooms'], axis=1)\n",
    "X_test = X_test.drop(['longitude', 'latitude', 'total_bedrooms', 'total_rooms'], axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc13923-cb8e-42bf-89f8-e32818499463",
   "metadata": {},
   "source": [
    "## Please report old and new RMSE below\n",
    "\n",
    "What is the RMSE of the two feature engineering ways respectively?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3177730a-317e-43d4-9399-43fc490de71c",
   "metadata": {},
   "source": [
    "RMSE of the **old way** (dropping features directly): xxxx.xxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d88c2c-7a98-420e-a77e-62815f93ba03",
   "metadata": {},
   "source": [
    "RMSE of the **new way** (replacing with new features): xxxx.xxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27c3592-873c-4565-a762-2d09b5f470a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Part 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358214e7-bd28-4673-a5e6-c286fc43a94f",
   "metadata": {},
   "source": [
    "Please export the models you trained by the first and second feature engineering methods respectively using the following code:\n",
    "1. For the first model\n",
    "   ```python\n",
    "   dump(model, 'drop_feature.joblib') \n",
    "   ```\n",
    "2. For the second model\n",
    "   ```python\n",
    "   dump(model,'replace_feature.joblib')\n",
    "   ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
